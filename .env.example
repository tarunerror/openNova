# Environment Variables Template
# Copy this file to .env and fill in your API keys

# LLM Provider Configuration
# Choose one: ollama (local), openai, anthropic, google

# OpenAI (if using OpenAI models)
OPENAI_API_KEY=sk-your-openai-key-here

# Anthropic (if using Claude models)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here

# Google (if using Gemini models)
GOOGLE_API_KEY=your-google-api-key-here

# Ollama (if using local models)
OLLAMA_HOST=http://localhost:11434

# Optional: Logging Level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO
